{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Daisuke Yoda'\n",
    "__Date__ = 'January 2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "__dir__ = os.getcwd()[:-11]\n",
    "\n",
    "from chainer import Chain, Variable, optimizers, serializers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word):\n",
    "    word_index = [ord (char) - 97 for char in word]\n",
    "    return word_index\n",
    "\n",
    "\n",
    "def one_hot_encoding(indices, n_class=27):\n",
    "    return np.eye(n_class)[indices]\n",
    "\n",
    "def padding(sentences):\n",
    "    max_len = np.max([len(s) for s in sentences])\n",
    "    paded_vec = []\n",
    "    for sentence in sentences:\n",
    "        pad_len = max_len - len(sentence)\n",
    "        pad_vec = [26] * pad_len\n",
    "        sentence.extend(pad_vec)\n",
    "        paded_vec.append(sentence)\n",
    "\n",
    "    return np.array(paded_vec, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Chain):\n",
    "    def __init__(self, in_size, hidden_size,out_size):\n",
    "        super(LSTM, self).__init__(\n",
    "            h1 = L.NStepLSTM (\n",
    "                n_layers=1,\n",
    "                in_size=in_size,\n",
    "                out_size=hidden_size,\n",
    "                dropout=0.5),\n",
    "            hy = L.Linear(hidden_size*17,out_size))\n",
    "\n",
    "\n",
    "    def __call__(self,input_data,hx=None):\n",
    "        if np.any(hx):\n",
    "            hx = hx.reshape(1,-1,self.h1.out_size)\n",
    "        input_x = [Variable(x) for x in input_data]\n",
    "        hx,cx,y = self.h1(hx,None,input_x)\n",
    "        y2 = [F.concat(x, axis=0) for x in F.pad_sequence(y,length=17, padding=0.)]\n",
    "        y2 = F.concat([F.expand_dims(x,axis=0) for x in y2],axis=0)\n",
    "\n",
    "        out = self.hy(y2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self,word,hx=None):\n",
    "        test_vec = word_to_index(word)\n",
    "        test_vec = one_hot_encoding(test_vec).astype(np.float32)\n",
    "        res = self([test_vec],hx)[0]\n",
    "        return F.argmax(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Dataset (Random)\n",
    "### (words and their split point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wearing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>societies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consultation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regulated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5    6    7    8    9    10   11  12  \\\n",
       "wearing       0.0  0.0  0.0  1.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN NaN   \n",
       "societies     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  NaN  NaN  NaN NaN   \n",
       "list          0.0  0.0  0.0  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN NaN   \n",
       "consultation  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 NaN   \n",
       "regulated     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  NaN  NaN  NaN NaN   \n",
       "\n",
       "              13  14  15  16  \n",
       "wearing      NaN NaN NaN NaN  \n",
       "societies    NaN NaN NaN NaN  \n",
       "list         NaN NaN NaN NaN  \n",
       "consultation NaN NaN NaN NaN  \n",
       "regulated    NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(__dir__ + 'data/split_point_2.csv', index_col=0)\n",
    "df = df[np.random.permutation (df.columns)]\n",
    "df.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the glove data and Using it for all words into glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(__dir__ + 'data/glove.6B.200d.bin')\n",
    "word_vec = np.array([word_vectors.get_vector(word) for word in df.columns], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = [word_to_index(x) for x in df.columns]\n",
    "original_data = [one_hot_encoding(x).astype (np.float32) for x in original_data]\n",
    "split_point = np.nan_to_num(df, 0).T\n",
    "\n",
    "dataX = original_data\n",
    "dataY = split_point.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(27, 200, 17)\n",
    "serializers.load_npz(__dir__ + 'data/model5.npz',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the accuracy\n",
    "\n",
    "### REMARK:\n",
    "### This model is for windows OS and LInux OS, not for Mac OS\n",
    "### Also the dataset includes both training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.91904115784713\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*np.sum(np.argmax(model(dataX).data, axis=1)==np.argmax(dataY,axis=1))/len(dataX)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference between model1 and model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yields', 'face', 'slower', 'policies', 'course', 'delay',\n",
       "       'representing', 'examined', 'promises', 'propose',\n",
       "       ...\n",
       "       'feature', 'features', 'occupied', 'asian', 'win', 'urges', 'aroused',\n",
       "       'embassies', 'does', 'weaken'],\n",
       "      dtype='object', length=245)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = np.where(np.argmax(model(dataX).data, axis=1)!=np.argmax(dataY,axis=1))[0]\n",
    "model1_split = df[df.columns[ix]].apply(np.argmax)\n",
    "model1_split.name = 'model_1'\n",
    "split_result = pd.DataFrame(model1_split)\n",
    "split_result['model_4'] = np.argmax(model(dataX).data, axis=1)[ix]\n",
    "split_result.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
