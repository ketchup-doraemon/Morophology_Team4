{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Daisuke Yoda'\n",
    "__Date__ = 'January 2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "__dir__ = os.getcwd()[:-11]\n",
    "\n",
    "from chainer import Chain, Variable, optimizers, serializers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word):\n",
    "    word_index = [ord (char) - 97 for char in word]\n",
    "    return word_index\n",
    "\n",
    "\n",
    "def one_hot_encoding(indices, n_class=27):\n",
    "    return np.eye(n_class)[indices]\n",
    "\n",
    "def padding(sentences):\n",
    "    max_len = np.max([len(s) for s in sentences])\n",
    "    paded_vec = []\n",
    "    for sentence in sentences:\n",
    "        pad_len = max_len - len(sentence)\n",
    "        pad_vec = [26] * pad_len\n",
    "        sentence.extend(pad_vec)\n",
    "        paded_vec.append(sentence)\n",
    "\n",
    "    return np.array(paded_vec, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Chain):\n",
    "    def __init__(self, in_size, hidden_size,out_size):\n",
    "        super(LSTM, self).__init__(\n",
    "            h1 = L.NStepLSTM (\n",
    "                n_layers=1,\n",
    "                in_size=in_size,\n",
    "                out_size=hidden_size,\n",
    "                dropout=0.5),\n",
    "            hy = L.Linear(hidden_size*17,out_size))\n",
    "\n",
    "\n",
    "    def __call__(self,input_data,hx=None):\n",
    "        if np.any(hx):\n",
    "            hx = hx.reshape(1,-1,self.h1.out_size)\n",
    "        input_x = [Variable(x) for x in input_data]\n",
    "        hx,cx,y = self.h1(hx,None,input_x)\n",
    "        y2 = [F.concat(x, axis=0) for x in F.pad_sequence(y,length=17, padding=0.)]\n",
    "        y2 = F.concat([F.expand_dims(x,axis=0) for x in y2],axis=0)\n",
    "\n",
    "        out = self.hy(y2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self,word,hx=None):\n",
    "        test_vec = word_to_index(word)\n",
    "        test_vec = one_hot_encoding(test_vec).astype(np.float32)\n",
    "        res = self([test_vec],hx)[0]\n",
    "        return F.argmax(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Dataset (Random)\n",
    "### (words and their split point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wearing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>societies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consultation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regulated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5    6    7    8    9    10   11  12  \\\n",
       "wearing       0.0  0.0  0.0  1.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN NaN   \n",
       "societies     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  NaN  NaN  NaN NaN   \n",
       "list          0.0  0.0  0.0  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN NaN   \n",
       "consultation  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 NaN   \n",
       "regulated     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  NaN  NaN  NaN NaN   \n",
       "\n",
       "              13  14  15  16  \n",
       "wearing      NaN NaN NaN NaN  \n",
       "societies    NaN NaN NaN NaN  \n",
       "list         NaN NaN NaN NaN  \n",
       "consultation NaN NaN NaN NaN  \n",
       "regulated    NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(__dir__ + 'data/split_point_2.csv', index_col=0)\n",
    "df = df[np.random.permutation (df.columns)]\n",
    "df.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the glove data and Using it for all words into glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(__dir__ + 'data/glove.6B.200d.bin')\n",
    "word_vec = np.array([word_vectors.get_vector(word) for word in df.columns], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = [word_to_index(x) for x in df.columns]\n",
    "original_data = [one_hot_encoding(x).astype (np.float32) for x in original_data]\n",
    "split_point = np.nan_to_num(df, 0).T\n",
    "\n",
    "dataX = original_data\n",
    "dataY = split_point.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(27, 200, 17)\n",
    "serializers.load_npz(__dir__ + 'data/model5.npz',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the accuracy\n",
    "\n",
    "### REMARK:\n",
    "### This model is for windows OS and LInux OS, not for Mac OS\n",
    "### Also the dataset includes both training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.91904115784713\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*np.sum(np.argmax(model(dataX).data, axis=1)==np.argmax(dataY,axis=1))/len(dataX)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference between model1 and model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressures</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suite</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selection</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varying</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confrontation</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terminate</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_1  model_4\n",
       "had                  1        2\n",
       "code                 3        2\n",
       "pressures            7        6\n",
       "suite                4        3\n",
       "selection            5        8\n",
       "varying              2        3\n",
       "confrontation       12       10\n",
       "island               5        3\n",
       "terminate            8        7\n",
       "pass                 3        2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = np.where(np.argmax(model(dataX).data, axis=1)!=np.argmax(dataY,axis=1))[0]\n",
    "model1_split = df[df.columns[ix]].apply(np.argmax)\n",
    "model1_split.name = 'model_1'\n",
    "split_result = pd.DataFrame(model1_split)\n",
    "split_result['model_4'] = np.argmax(model(dataX).data, axis=1)[ix]\n",
    "split_result.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1: solv + e\n",
      "model4: solve + \n",
      "=====================\n",
      "model1: africa + n\n",
      "model4: african + \n",
      "=====================\n",
      "model1: var + ying\n",
      "model4: vary + ing\n",
      "=====================\n",
      "model1: prove + d\n",
      "model4: prov + ed\n",
      "=====================\n",
      "model1: arche + d\n",
      "model4: arch + ed\n",
      "=====================\n",
      "model1: leav + e\n",
      "model4: leave + \n",
      "=====================\n",
      "model1: episode + \n",
      "model4: episod + e\n",
      "=====================\n",
      "model1: yield + s\n",
      "model4: yiel + ds\n",
      "=====================\n",
      "model1: pressure + s\n",
      "model4: pressur + es\n",
      "=====================\n",
      "model1: propos + es\n",
      "model4: propose + s\n",
      "=====================\n",
      "model1: promis + e\n",
      "model4: promise + \n",
      "=====================\n",
      "model1: tax + es\n",
      "model4: taxe + s\n",
      "=====================\n",
      "model1: represent + ing\n",
      "model4: represen + ting\n",
      "=====================\n",
      "model1: code + \n",
      "model4: cod + e\n",
      "=====================\n",
      "model1: base + \n",
      "model4: bas + e\n",
      "=====================\n",
      "model1: type + \n",
      "model4: typ + e\n",
      "=====================\n",
      "model1: operat + es\n",
      "model4: operate + s\n",
      "=====================\n",
      "model1: estimate + d\n",
      "model4: estimat + ed\n",
      "=====================\n",
      "model1: respond + \n",
      "model4: respon + d\n",
      "=====================\n",
      "model1: rifle + \n",
      "model4: rifl + e\n",
      "=====================\n",
      "model1: terminate + d\n",
      "model4: terminat + ed\n",
      "=====================\n",
      "model1: giv + es\n",
      "model4: give + s\n",
      "=====================\n",
      "model1: pursu + ed\n",
      "model4: pursued + \n",
      "=====================\n",
      "model1: deep + er\n",
      "model4: deeper + \n",
      "=====================\n",
      "model1: stay + \n",
      "model4: sta + y\n",
      "=====================\n",
      "model1: alleged + ly\n",
      "model4: allegedl + y\n",
      "=====================\n",
      "model1: command + er\n",
      "model4: commander + \n",
      "=====================\n",
      "model1: discrepanc + ies\n",
      "model4: discrepancie + s\n",
      "=====================\n",
      "model1: play + er\n",
      "model4: player + \n",
      "=====================\n",
      "model1: winn + ers\n",
      "model4: winner + s\n",
      "=====================\n",
      "model1: dividend + \n",
      "model4: divide + nd\n",
      "=====================\n",
      "model1: rais + es\n",
      "model4: raise + s\n",
      "=====================\n",
      "model1: hop + es\n",
      "model4: hope + s\n",
      "=====================\n",
      "model1: violat + ions\n",
      "model4: violation + s\n",
      "=====================\n",
      "model1: fac + es\n",
      "model4: face + s\n",
      "=====================\n",
      "model1: young + er\n",
      "model4: younger + \n",
      "=====================\n",
      "model1: expire + d\n",
      "model4: expir + ed\n",
      "=====================\n",
      "model1: dinner + s\n",
      "model4: dinners + \n",
      "=====================\n",
      "model1: var + ied\n",
      "model4: vari + ed\n",
      "=====================\n",
      "model1: representative + s\n",
      "model4: represent + atives\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "def print_split_point(dataframe):\n",
    "    print('model1:',dataframe.name[:dataframe.ix[0]+1],'+',dataframe.name[dataframe.ix[0]+1:])\n",
    "    print('model4:',dataframe.name[:dataframe.ix[1]+1],'+',dataframe.name[dataframe.ix[1]+1:])\n",
    "    \n",
    "split_result_sample = split_result.sample(40)\n",
    "for i in range(40):\n",
    "    print_split_point(split_result_sample.iloc[i])\n",
    "    print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
