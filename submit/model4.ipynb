{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Team_4'\n",
    "__Date__ = 'January 2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "__dir__ = os.getcwd()[:-11]\n",
    "\n",
    "from chainer import Chain, Variable, optimizers, serializers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word):\n",
    "    word_index = [ord (char) - 97 for char in word]\n",
    "    return word_index\n",
    "\n",
    "\n",
    "def one_hot_encoding(indices, n_class=27):\n",
    "    return np.eye(n_class)[indices]\n",
    "\n",
    "def padding(sentences):\n",
    "    max_len = np.max([len(s) for s in sentences])\n",
    "    paded_vec = []\n",
    "    for sentence in sentences:\n",
    "        pad_len = max_len - len(sentence)\n",
    "        pad_vec = [26] * pad_len\n",
    "        sentence.extend(pad_vec)\n",
    "        paded_vec.append(sentence)\n",
    "\n",
    "    return np.array(paded_vec, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Chain):\n",
    "    def __init__(self, in_size, hidden_size,out_size):\n",
    "        super(LSTM, self).__init__(\n",
    "            h1 = L.NStepLSTM (\n",
    "                n_layers=1,\n",
    "                in_size=in_size,\n",
    "                out_size=hidden_size,\n",
    "                dropout=0.5),\n",
    "            hy = L.Linear(hidden_size*17,out_size))\n",
    "\n",
    "\n",
    "    def __call__(self,input_data,hx=None):\n",
    "        if np.any(hx):\n",
    "            hx = hx.reshape(1,-1,self.h1.out_size)\n",
    "        input_x = [Variable(x) for x in input_data]\n",
    "        hx,cx,y = self.h1(hx,None,input_x)\n",
    "        y2 = [F.concat(x, axis=0) for x in F.pad_sequence(y,length=17, padding=0.)]\n",
    "        y2 = F.concat([F.expand_dims(x,axis=0) for x in y2],axis=0)\n",
    "\n",
    "        out = self.hy(y2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self,word,hx=None):\n",
    "        test_vec = word_to_index(word)\n",
    "        test_vec = one_hot_encoding(test_vec).astype(np.float32)\n",
    "        res = self([test_vec],hx)[0]\n",
    "        return F.argmax(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Dataset (Random)\n",
    "### (words and their splitting point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tanks</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adopt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7   8   9   10  11  12  13  14  \\\n",
       "tanks    0.0  0.0  0.0  0.0  0.0  1.0  NaN  NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "purpose  0.0  0.0  0.0  0.0  0.0  1.0  0.0  NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "winning  0.0  0.0  0.0  0.0  0.0  0.0  1.0  NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "think    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 NaN NaN NaN NaN NaN NaN NaN   \n",
       "adopt    0.0  0.0  1.0  NaN  NaN  NaN  NaN  NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "         15  16  \n",
       "tanks   NaN NaN  \n",
       "purpose NaN NaN  \n",
       "winning NaN NaN  \n",
       "think   NaN NaN  \n",
       "adopt   NaN NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(__dir__ + 'data/split_point_2.csv', index_col=0)\n",
    "df = df[np.random.permutation (df.columns)]\n",
    "df.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the glove data and Use it to converr all the words into glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(__dir__ + 'data/glove.6B.200d.bin')\n",
    "word_vec = np.array([word_vectors.get_vector(word) for word in df.columns], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = [word_to_index(x) for x in df.columns]\n",
    "original_data = [one_hot_encoding(x).astype (np.float32) for x in original_data]\n",
    "split_point = np.nan_to_num(df, 0).T\n",
    "\n",
    "dataX = original_data\n",
    "dataY = split_point.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(27, 200, 17)\n",
    "serializers.load_npz(__dir__ + 'data/model5.npz',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the accuracy\n",
    "\n",
    "### REMARK:\n",
    "### This model is for windows OS and LInux OS, not for Mac OS\n",
    "### Also the dataset includes both training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 15.151515151515152\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*np.sum(np.argmax(model(dataX).data, axis=1)==np.argmax(dataY,axis=1))/len(dataX)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
