{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Team_4'\n",
    "__Date__ = 'December 2018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "__dir__ = os.getcwd()[:-11]\n",
    "\n",
    "from chainer import Chain, Variable, optimizers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The three networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class First_Network(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super(First_Network, self).__init__(\n",
    "            hh = L.Linear(in_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size, out_size),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = Variable(x)\n",
    "        h = self.hh(x)\n",
    "        h = F.dropout(h,0.3)\n",
    "        h = F.relu(h)\n",
    "        y = self.hy(h)\n",
    "        y = F.softmax(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class Second_Network(Chain):\n",
    "    def __init__(self,vocab_size, in_size, out_size):\n",
    "        super(Second_Network, self).__init__(\n",
    "            xh=L.EmbedID(vocab_size, in_size),\n",
    "            hh=L.LSTM(in_size, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Variable(x)\n",
    "        x = self.xh(x)\n",
    "        if self.i == 0:\n",
    "            self.x = x\n",
    "        y = self.hh(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __call__(self,word):\n",
    "        self.reset()\n",
    "        self.i = 0\n",
    "        if word == []:\n",
    "            return self.forward(np.array([0],dtype=np.int32))\n",
    "        \n",
    "        for char in word:\n",
    "            out = self.forward(char)\n",
    "            self.i += 1\n",
    "\n",
    "        return out\n",
    "\n",
    "    def reset(self):\n",
    "        self.hh.reset_state()\n",
    "\n",
    "\n",
    "class Third_Network(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super(Third_Network, self).__init__(\n",
    "            hh1 = L.Linear(in_size, hidden_size),\n",
    "            hh2 =L.Linear(in_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size*2, out_size),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x1,x2,t):\n",
    "        t = Variable(t)\n",
    "        h1 = self.hh1(x1)\n",
    "        h2 = self.hh2(x2)\n",
    "        h1 = F.dropout(h1,0.3)\n",
    "        h2 = F.dropout(h2, 0.3)\n",
    "        h1 = F.relu(h1)\n",
    "        h2 = F.relu(h2)\n",
    "        h = F.concat([h1, h2])\n",
    "        out = self.hy(h)\n",
    "        out = F.tanh(out)\n",
    "        out = F.normalize(out)\n",
    "\n",
    "        return F.mean_squared_error(out,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word):\n",
    "    word_index = [ord (char) - 97 for char in word]\n",
    "    return word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = KeyedVectors.load_word2vec_format(__dir__ + 'data/glove.6B.100d.bin')\n",
    "original_word = 'created'\n",
    "glove_vec = dic.get_vector(original_word).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0x171885da0b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_net = First_Network(100,30,len(original_word))\n",
    "second_net = Second_Network(27,30, 50)\n",
    "second_net2 = Second_Network(27, 30, 50)\n",
    "third_net = Third_Network(50, 50, 100)\n",
    "\n",
    "optimizer1 = optimizers.Adam()\n",
    "optimizer1.setup(first_net)\n",
    "\n",
    "optimizer2 = optimizers.Adam()\n",
    "optimizer2.setup(first_net)\n",
    "\n",
    "optimizer3 = optimizers.Adam()\n",
    "optimizer3.setup(first_net)\n",
    "\n",
    "optimizer4 = optimizers.Adam()\n",
    "optimizer4.setup(first_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_record = []\n",
    "f1_record = []\n",
    "    for i in range(50):\n",
    "        first_net.cleargrads()\n",
    "        second_net.cleargrads()\n",
    "        second_net2.cleargrads()\n",
    "        third_net.cleargrads()\n",
    "        \n",
    "        f1 = first_net(glove_vec)\n",
    "        split_ix = np.argmax(f1.data,axis=1) + 1\n",
    "\n",
    "        word1 = original_word[:np.int(split_ix)]\n",
    "        word2 = original_word[np.int(split_ix):]\n",
    "\n",
    "        vec1 = [np.array([ord(char) - 96], dtype=np.int32) for char in word1]\n",
    "        y1 = second_net(vec1)\n",
    "\n",
    "        vec2 = [np.array([ord(char) - 96], dtype=np.int32) for char in word2]\n",
    "        y2 = second_net2(vec2)\n",
    "\n",
    "\n",
    "        loss = third_net(y1,y2,glove_vec)\n",
    "        loss_record.append(float(loss.data))\n",
    "        loss.backward(retain_grad=True)\n",
    "\n",
    "\n",
    "        optimizer4.update()\n",
    "        optimizer3.update()\n",
    "        optimizer2.update()\n",
    "\n",
    "        f1_loss = F.concat([second_net.x.grad,second_net2.x.grad])\n",
    "        f1_loss = F.sum(F.absolute(f1_loss))\n",
    "        f1_record.append(float(f1_loss.data))\n",
    "        f1.grad = (f1 * f1_loss.data).data\n",
    "        #f1.grad = (f1 * loss.data).data\n",
    "        f1.unchain_backward()\n",
    "        f1.backward(retain_grad=True)\n",
    "        optimizer1.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
